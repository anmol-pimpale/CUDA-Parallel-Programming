{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Anji_TZduPmR",
        "outputId": "bb535ee1-cdbe-450f-c81f-d5545af93e12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pycuda\n",
            "  Downloading pycuda-2024.1.tar.gz (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pytools>=2011.2 (from pycuda)\n",
            "  Downloading pytools-2024.1.3-py2.py3-none-any.whl (87 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.4/87.4 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting appdirs>=1.4.0 (from pycuda)\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting mako (from pycuda)\n",
            "  Downloading Mako-1.3.5-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from pytools>=2011.2->pycuda) (4.2.2)\n",
            "Requirement already satisfied: typing-extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pytools>=2011.2->pycuda) (4.11.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from mako->pycuda) (2.1.5)\n",
            "Building wheels for collected packages: pycuda\n",
            "  Building wheel for pycuda (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycuda: filename=pycuda-2024.1-cp310-cp310-linux_x86_64.whl size=661204 sha256=108d85bd816adc67ca81fdbf1996e03815a14bc84a79e2bb700cca8ee8f71495\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/34/d2/9a349255a4eca3a486d82c79d21e138ce2ccd90f414d9d72b8\n",
            "Successfully built pycuda\n",
            "Installing collected packages: appdirs, pytools, mako, pycuda\n",
            "Successfully installed appdirs-1.4.4 mako-1.3.5 pycuda-2024.1 pytools-2024.1.3\n"
          ]
        }
      ],
      "source": [
        "!pip install pycuda"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile hello.py\n",
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "from pycuda.compiler import SourceModule\n",
        "import numpy as np\n",
        "\n",
        "cuda_code=\"\"\"\n",
        "__global__ void return_data(char *output){\n",
        "  const char msg[]=\"hello-world\";\n",
        "  int idx=threadIdx.x + blockIdx.x * blockDim.x;\n",
        "  if(idx < sizeof(msg)){\n",
        "    output[idx]=msg[idx];\n",
        "  }\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "cuda_module=SourceModule(cuda_code)\n",
        "return_data_kernel=cuda_module.get_function(\"return_data\")\n",
        "\n",
        "output_size=15  #length of the \"hello-world\" string + null terminator\n",
        "output_gpu = cuda.mem_alloc(output_size * np.dtype(np.uint8).itemsize)\n",
        "\n",
        "block_dim=(32,1,1)\n",
        "grid_dim=(1,1)\n",
        "\n",
        "output_host=np.empty(output_size,dtype=np.uint8)\n",
        "output_ptr = cuda.to_device(output_host)\n",
        "\n",
        "return_data_kernel(output_ptr, block=block_dim, grid=grid_dim)\n",
        "\n",
        "cuda.memcpy_dtoh(output_host,output_ptr)\n",
        "\n",
        "output_str= ''.join(chr(c)for c in output_host)\n",
        "print(output_str)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYXYpGEIu4Vb",
        "outputId": "0f1c178f-2141-4b5e-ccf5-f9ed29919d9e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing hello.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python hello.py"
      ],
      "metadata": {
        "id": "sueFrafmvqrU",
        "outputId": "7120eebf-dc13-4682-8c0a-dfffd2df9f45",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello-world\u0000\u0000\u0000\u0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile pycuda_add.py\n",
        "import numpy as np\n",
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "from pycuda.compiler import SourceModule\n",
        "\n",
        "#CUDA kernel code for array addition\n",
        "cuda_code = \"\"\"\n",
        "__global__ void add_arrays(int *a,int *b,int *c,int size) {\n",
        "  int tid = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "\n",
        "  if(tid < size) {\n",
        "    c[tid] = a[tid] + b[tid];\n",
        "  }\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "#Host data\n",
        "a_host = np.array([1,2,3], dtype=np.int32)\n",
        "b_host = np.array([4,5,6], dtype=np.int32)\n",
        "size = len(a_host)\n",
        "\n",
        "#Device data\n",
        "a_device = cuda.mem_alloc(a_host.nbytes)\n",
        "b_device = cuda.mem_alloc(b_host.nbytes)\n",
        "c_device = cuda.mem_alloc(a_host.nbytes)\n",
        "\n",
        "#Copy data to device\n",
        "cuda.memcpy_htod(a_device, a_host)\n",
        "cuda.memcpy_htod(b_device, b_host)\n",
        "\n",
        "#Load the CUDA module\n",
        "cuda_module = SourceModule(cuda_code)\n",
        "add_arrays_kernel = cuda_module.get_function(\"add_arrays\")\n",
        "\n",
        "#Set up block and grid dimensions\n",
        "block_dim = (size,1, 1)\n",
        "grid_dim = (1,1)\n",
        "\n",
        "#Launch the CUDA kernel\n",
        "add_arrays_kernel(a_device, b_device, c_device, np.int32(size), block=block_dim, grid=grid_dim)\n",
        "\n",
        "#Copy the result back to the host\n",
        "c_host = np.empty_like(a_host)\n",
        "cuda.memcpy_dtoh(c_host, c_device)\n",
        "\n",
        "#Display the result\n",
        "print(\"Array A: \",a_host)\n",
        "print(\"Array B: \",b_host)\n",
        "print(\"Result Array C: \",c_host)"
      ],
      "metadata": {
        "id": "d-9m2EbdvxrX",
        "outputId": "732de15c-ff67-478c-b75f-f24791291348",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting pycuda_add.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python pycuda_add.py"
      ],
      "metadata": {
        "id": "zuhRBCzxwYBD",
        "outputId": "8038ca84-7185-4b00-ccb5-3f33bdc7ed25",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Array A:  [1 2 3]\n",
            "Array B:  [4 5 6]\n",
            "Result Array C:  [5 7 9]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile pycuda_addition.py\n",
        "import numpy as np\n",
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "from pycuda.compiler import SourceModule\n",
        "import time\n",
        "\n",
        "# CUDA kernel code for array addition\n",
        "cuda_code = \"\"\"\n",
        "__global__ void add_arrays(float *a, float *b, float *c, int size) {\n",
        "  int tid = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "\n",
        "  if(tid < size) {\n",
        "    c[tid] = a[tid] + b[tid];\n",
        "  }\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "# CPU array addition\n",
        "def cpu_add_arrays(a, b):\n",
        "  return a + b\n",
        "\n",
        "# GPU array addition\n",
        "def gpu_add_arrays(a_gpu, b_gpu, result_gpu, size):\n",
        "  block_size = 256\n",
        "  grid_size = (size + block_size - 1) // block_size\n",
        "\n",
        "  add_arrays_cuda(a_gpu, b_gpu, result_gpu, np.int32(size), block=(block_size, 1, 1), grid=(grid_size, 1))\n",
        "\n",
        "# Generate random arrays\n",
        "size = 27000 * 27000\n",
        "a_cpu = np.random.rand(size).astype(np.float32)\n",
        "b_cpu = np.random.rand(size).astype(np.float32)\n",
        "result_cpu = np.zeros_like(a_cpu)\n",
        "\n",
        "# Allocate GPU memory\n",
        "a_gpu = cuda.mem_alloc(a_cpu.nbytes)\n",
        "b_gpu = cuda.mem_alloc(b_cpu.nbytes)\n",
        "result_gpu = cuda.mem_alloc(result_cpu.nbytes)\n",
        "\n",
        "# Copy data to GPU\n",
        "cuda.memcpy_htod(a_gpu, a_cpu)\n",
        "cuda.memcpy_htod(b_gpu, b_cpu)\n",
        "\n",
        "# Compile the CUDA code\n",
        "mod = SourceModule(cuda_code)\n",
        "add_arrays_cuda = mod.get_function(\"add_arrays\")\n",
        "\n",
        "# Perform CPU array addition and measure time\n",
        "start_time_cpu = time.time()\n",
        "result_cpu = cpu_add_arrays(a_cpu, b_cpu)\n",
        "end_time_cpu = time.time()\n",
        "time_cpu = end_time_cpu - start_time_cpu\n",
        "\n",
        "# Perform GPU array addition and measure time\n",
        "start_time_gpu = time.time()\n",
        "gpu_add_arrays(a_gpu, b_gpu, result_gpu, size)\n",
        "cuda.Context.synchronize()\n",
        "end_time_gpu = time.time()\n",
        "time_gpu = end_time_gpu - start_time_gpu\n",
        "\n",
        "# Copy result from GPU to host\n",
        "cuda.memcpy_dtoh(result_cpu, result_gpu)\n",
        "\n",
        "# Display result and time taken\n",
        "print(f\"Time taken on CPU: {time_cpu} seconds\")\n",
        "print(f\"Time taken on GPU: {time_gpu} seconds\")"
      ],
      "metadata": {
        "id": "y14kfSG6z7z8",
        "outputId": "c6ce4bcd-67cf-4dec-bbfe-66fd9c577567",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting pycuda_addition.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python pycuda_addition.py"
      ],
      "metadata": {
        "id": "Ut22GjYj5RL8",
        "outputId": "a9087632-531d-4dff-9009-825226240af4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time taken on CPU: 1.1193950176239014 seconds\n",
            "Time taken on GPU: 0.03608560562133789 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile pycuda_one_dimention.py\n",
        "import numpy as np\n",
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "from pycuda.compiler import SourceModule\n",
        "import time\n",
        "\n",
        "# CUDA kernel code for array addition\n",
        "cuda_code = \"\"\"\n",
        "__global__ void add_arrays(float *a, float *b, float *c, int size) {\n",
        "  int tid = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "\n",
        "  if(tid < size) {\n",
        "    c[tid] = a[tid] + b[tid];\n",
        "  }\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "# CPU array addition\n",
        "def cpu_add_arrays(a, b):\n",
        "  return a + b\n",
        "\n",
        "# GPU array addition\n",
        "def gpu_add_arrays(a_gpu, b_gpu, result_gpu, size):\n",
        "  block_size = 256\n",
        "  grid_size = (size + block_size - 1) // block_size\n",
        "\n",
        "  add_arrays_cuda(a_gpu, b_gpu, result_gpu, np.int32(size), block=(block_size, 1, 1), grid=(grid_size, 1))\n",
        "\n",
        "# Generate random arrays\n",
        "size = 27000 * 27000\n",
        "a_cpu = np.random.rand(size).astype(np.float32)\n",
        "b_cpu = np.random.rand(size).astype(np.float32)\n",
        "result_cpu = np.zeros_like(a_cpu)\n",
        "\n",
        "# Allocate GPU memory\n",
        "a_gpu = cuda.mem_alloc(a_cpu.nbytes)\n",
        "b_gpu = cuda.mem_alloc(b_cpu.nbytes)\n",
        "result_gpu = cuda.mem_alloc(result_cpu.nbytes)\n",
        "\n",
        "# Copy data to GPU\n",
        "cuda.memcpy_htod(a_gpu, a_cpu)\n",
        "cuda.memcpy_htod(b_gpu, b_cpu)\n",
        "\n",
        "# Compile the CUDA code\n",
        "mod = SourceModule(cuda_code)\n",
        "add_arrays_cuda = mod.get_function(\"add_arrays\")\n",
        "\n",
        "# Perform CPU array addition and measure time\n",
        "start_time_cpu = time.time()\n",
        "result_cpu = cpu_add_arrays(a_cpu, b_cpu)\n",
        "end_time_cpu = time.time()\n",
        "time_cpu = end_time_cpu - start_time_cpu\n",
        "\n",
        "# Perform GPU array addition and measure time\n",
        "start_time_gpu = time.time()\n",
        "gpu_add_arrays(a_gpu, b_gpu, result_gpu, size)\n",
        "cuda.Context.synchronize()\n",
        "end_time_gpu = time.time()\n",
        "time_gpu = end_time_gpu - start_time_gpu\n",
        "\n",
        "# Copy result from GPU to host\n",
        "cuda.memcpy_dtoh(result_cpu, result_gpu)\n",
        "\n",
        "# Display result and time taken\n",
        "print(f\"Time taken on CPU: {time_cpu} seconds\")\n",
        "print(f\"Time taken on GPU: {time_gpu} seconds\")"
      ],
      "metadata": {
        "id": "Nv9xOgUI8xCW",
        "outputId": "3714df74-5bda-4dbb-81d2-c590f7c2b2ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting pycuda_one_dimention.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python pycuda_one_dimention.py"
      ],
      "metadata": {
        "id": "0r4EzZUy8_MU",
        "outputId": "2022a14a-48df-405c-b908-82747807781f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time taken on CPU: 1.136056900024414 seconds\n",
            "Time taken on GPU: 0.03370523452758789 seconds\n"
          ]
        }
      ]
    }
  ]
}